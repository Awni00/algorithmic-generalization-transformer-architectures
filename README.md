<div align="center">

# Unlocking Out-of-Distribution Generalization in Transformers via Recursive Latent Space Reasoning

**Awni Altabaa** Â· **Siyu Chen** Â· **John Lafferty** Â· **Zhuoran Yang**

*Enhancing Transformer architectures with recursive latent space reasoning mechanisms for robust algorithmic generalization*

<!-- TODO: add arxiv link -->

</div>

---

## ðŸ’¡ Abstract

Systematic, compositional generalization beyond the training distribution remains a core challenge in machine learningâ€”and a critical bottleneck for the emergent reasoning abilities of modern language models.

This work investigates out-of-distribution (OOD) generalization in Transformer networks using a GSM8K-style modular arithmetic on computational graphs task as a testbed.

<!-- 
### â­ Key Contributions
-->
We introduce and explore **four architectural mechanisms** aimed at enhancing OOD generalization:

1. **ðŸ”„ Input-adaptive recurrence** - Recurrent architecture that scales computation through input-adaptive recurrence.
2. **ðŸ“š Algorithmic supervision** - Structured learning objectives that encode algorithmic knowledge  
3. **âš“ Anchored latent representations** - Discrete bottlenecks for stable feature learning
4. **ðŸ”§ Explicit error-correction mechanism** - Built-in self-correction capabilities
<!--
### ðŸ“Š Results
-->
Collectively, these mechanisms yield an architectural approach for **native and scalable latent space reasoning** in Transformer networks with robust algorithmic generalization capabilities. We complement these empirical results with a detailed **mechanistic interpretability analysis** that reveals how these mechanisms give rise to robust OOD generalization abilities.

---
<!-- 
## ðŸ—‚ï¸ Repository Structure

```
ðŸ“ algorithmic-generalization-transformer-architectures/
â”œâ”€â”€ ðŸ“„ LICENSE                          # Project license
â”œâ”€â”€ ðŸ“„ README.md                        # This file
â”œâ”€â”€ ðŸ“ experiments/                     # Main experimental code
â”‚   â”œâ”€â”€ ðŸ dag_generator.py            # Computational graph generation
â”‚   â”œâ”€â”€ ðŸ generate_data.py            # Data generation utilities
â”‚   â”œâ”€â”€ ðŸ model.py                    # Core model implementations
â”‚   â”œâ”€â”€ ðŸ“„ readme.md                   # Detailed experiment instructions
â”‚   â”œâ”€â”€ ðŸ tokenizers.py               # Custom tokenization methods
â”‚   â”œâ”€â”€ ðŸ train.py                    # Main training script
â”‚   â”œâ”€â”€ ðŸ utils.py                    # Utility functions
â”‚   â”œâ”€â”€ ðŸ“ baselines/                  # Baseline model implementations
â”‚   â”‚   â”œâ”€â”€ ðŸ baseline_cot_train.py   # Chain-of-thought baseline training
â”‚   â”‚   â”œâ”€â”€ ðŸ baseline_models.py      # Standard baseline architectures
â”‚   â”‚   â”œâ”€â”€ ðŸ baseline_train.py       # General baseline training
â”‚   â”‚   â””â”€â”€ ðŸ generate_cot_data.py    # CoT data generation
â”‚   â”œâ”€â”€ ðŸ“ checkpoints/                # Saved model checkpoints
â”‚   â”‚   â””â”€â”€ ðŸ“ demo_group-demo_run/    # Example checkpoint
â”‚   â”œâ”€â”€ ðŸ“ configs/                    # Runtime configuration files
â”‚   â”œâ”€â”€ ðŸ“ data/                       # Generated datasets
â”‚   â”‚   â””â”€â”€ ðŸ“ Tr32Test128-ADD/        # Example dataset (32â†’128 nodes, ADD operations)
â”‚   â”‚       â”œâ”€â”€ ðŸ—ƒï¸ train_data.pt       # Training dataset
â”‚   â”‚       â”œâ”€â”€ ðŸ—ƒï¸ val_data.pt         # Validation dataset
â”‚   â”‚       â””â”€â”€ ðŸ”§ tokenizer.pickle    # Associated tokenizer
â”‚   â”œâ”€â”€ ðŸ“ evaluation/                 # Model evaluation tools
â”‚   â”‚   â”œâ”€â”€ ðŸ eval_baseline_model.py  # Baseline model evaluation
â”‚   â”‚   â”œâ”€â”€ ðŸ eval_cot_baseline_model.py # CoT baseline evaluation
â”‚   â”‚   â”œâ”€â”€ ðŸ eval_model.py           # Main model evaluation
â”‚   â”‚   â”œâ”€â”€ ðŸ eval_nointerm_model.py  # No-intermediate evaluation
â”‚   â”‚   â”œâ”€â”€ ðŸ““ generate_cot_depth_generalization_datasets.ipynb # CoT dataset notebook
â”‚   â”‚   â”œâ”€â”€ ðŸ generate_cot_depth_generalization_datasets.py # CoT dataset script
â”‚   â”‚   â”œâ”€â”€ ðŸ generate_depth_generalization_datasets.py # Main dataset generation
â”‚   â”‚   â”œâ”€â”€ ðŸ metric_utils.py         # Evaluation metrics
â”‚   â”‚   â”œâ”€â”€ ðŸ“ results/                # Evaluation results
â”‚   â”‚   â””â”€â”€ ðŸ“ val_datasets/           # Generated evaluation datasets
â”‚   â”‚       â””â”€â”€ ðŸ“ Tr32Test128/        # Example evaluation data
â”‚   â”œâ”€â”€ ðŸ“ example_configs/            # Example configuration files
â”‚   â”‚   â”œâ”€â”€ ðŸ“ CoT/                    # Chain-of-Thought configurations
â”‚   â”‚   â”‚   â”œâ”€â”€ âš™ï¸ data_config.yaml
â”‚   â”‚   â”‚   â”œâ”€â”€ âš™ï¸ model_config.yaml
â”‚   â”‚   â”‚   â””â”€â”€ âš™ï¸ train_config.yaml
â”‚   â”‚   â”œâ”€â”€ ðŸ“ feedforward_or_recurrent/ # Baseline configurations
â”‚   â”‚   â”‚   â”œâ”€â”€ âš™ï¸ data_config.yaml
â”‚   â”‚   â”‚   â”œâ”€â”€ âš™ï¸ model_config.yaml
â”‚   â”‚   â”‚   â””â”€â”€ âš™ï¸ train_config.yaml
â”‚   â”‚   â””â”€â”€ ðŸ“ our_method/             # Our method configurations
â”‚   â”‚       â”œâ”€â”€ âš™ï¸ data_config.yaml
â”‚   â”‚       â”œâ”€â”€ âš™ï¸ model_config.yaml
â”‚   â”‚       â””â”€â”€ âš™ï¸ train_config.yaml
â”‚   â”œâ”€â”€ ðŸ“ lightning_logs/             # Training logs
â”‚   â””â”€â”€ ðŸ“ model_interp/               # Model interpretability analysis
â”‚       â”œâ”€â”€ ðŸ conduct_controlled_exp.py # Controlled experiments
â”‚       â”œâ”€â”€ ðŸ““ transformer_model_interpretation_documented.ipynb # Analysis notebook
â”‚       â”œâ”€â”€ ðŸ“ base_config-Nodes32-ADD/ # Interpretation configuration
â”‚       â”‚   â”œâ”€â”€ âš™ï¸ data_config.yaml
â”‚       â”‚   â”œâ”€â”€ âš™ï¸ model_config.yaml
â”‚       â”‚   â””â”€â”€ âš™ï¸ train_config.yaml
â”‚       â”œâ”€â”€ ðŸ“ demo_checkpoint/         # Pre-trained model checkpoint
â”‚       â”‚   â””â”€â”€ ðŸ’¾ last.ckpt
â”‚       â””â”€â”€ ðŸ“ figures/                 # Visualization outputs
â”‚           â”œâ”€â”€ ðŸŒ L0_head_view.html
â”‚           â””â”€â”€ ðŸŒ L0_model_view.html
â””â”€â”€ ðŸ“ Simtransformer/                 # Simulation framework
    â”œâ”€â”€ ðŸ“„ README.md                   # Framework documentation
    â”œâ”€â”€ ðŸ“ configurations/             # Global configuration templates
    â”‚   â”œâ”€â”€ âš™ï¸ data_config_default.yaml
    â”‚   â”œâ”€â”€ âš™ï¸ model_config_default.yaml
    â”‚   â”œâ”€â”€ âš™ï¸ probe_config_default.yaml
    â”‚   â””â”€â”€ âš™ï¸ train_config_default.yaml
    â””â”€â”€ ðŸ“ simtransformer/             # Core framework code
        â”œâ”€â”€ ðŸ manager.py              # Experiment management
        â”œâ”€â”€ ðŸ model_bank.py           # Model registry
        â”œâ”€â”€ ðŸ model_base.py           # Base model classes
        â”œâ”€â”€ ðŸ module_base.py          # Base module classes
        â”œâ”€â”€ ðŸ“„ README.md               # Framework details
        â”œâ”€â”€ ðŸ utils.py                # Framework utilities
        â””â”€â”€ ðŸ“ configurations/         # Local configurations
            â”œâ”€â”€ âš™ï¸ data_config_default.yaml
            â”œâ”€â”€ âš™ï¸ model_config_default.yaml
            â”œâ”€â”€ âš™ï¸ probe_config_default.yaml
            â””â”€â”€ âš™ï¸ train_config_default.yaml
``` -->

### ðŸ“‚ Organization of Codebase

- **`experiments/`** - Contains the main experimental code for training and evaluating models with the proposed architectural mechanisms
- **`experiments/baselines/`** - Baseline implementations for comparison including chain-of-thought models and standard transformers
- **`experiments/evaluation/`** - Code for evaluating the algorithmic generalization capabilities of different methods.
- **`experiments/model_interp/`** - Mechanistic interpretability analysis tools and visualizations
- **`Simtransformer/`** - Helper framework implementing Transformer modules and related utilities

See [`experiments/readme.md`](experiments/readme.md) for instructions on how to reproduce the experiments in the paper.

<!-- TODO -->
<!-- ## Citation

```bibtex
@article{altabaa2025unlocking,
  title = {Unlocking Out-of-Distribution Generalization in Transformers via Recursive Latent Space Reasoning},
  author = {Altabaa, Awni and Chen, Siyu and Yang, Zhuoran and Lafferty, John},
  year = {2025},
  journal = {arXiv preprint arxiv:[...]}
}
``` -->
